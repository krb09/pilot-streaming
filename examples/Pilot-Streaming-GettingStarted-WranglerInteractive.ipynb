{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Pilot-Streaming on Wrangler\n",
    "\n",
    "In the first step we need to import all required packages and modules into the Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:59:21.386383Z",
     "start_time": "2017-12-28T17:59:21.364643Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pilot.streaming' from '/home/01131/tg804093/anaconda3/lib/python3.6/site-packages/pilot/streaming.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System Libraries\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    " \n",
    "\n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pilot-Compute Description is a simple key/value style description of the cluster environment that should be started. Alternatively, the commandline tool delivered with this package can be used:\n",
    "\n",
    "     pilot-streaming --resource=slurm://localhost --queue=normal --walltime=59 --number_cores=48 --framework spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:00:04.950564Z",
     "start_time": "2017-12-28T17:59:22.095228Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### Required Spark configuration that needs to be provided before pyspark is imported and JVM started\n",
    "#os.environ[\"SPARK_LOCAL_IP\"]='129.114.58.2' #must be done before pyspark is loaded\n",
    "import pyspark\n",
    "import os\n",
    "\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm+ssh://login1.wrangler.tacc.utexas.edu\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_of_nodes\": 2,\n",
    "    \"cores_per_node\": 48,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"spark\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Spark Cluster and Wait for Startup Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: Parsing job description: {'executable': 'python', 'arguments': ['-m', 'pilot.plugins.spark.bootstrap_spark'], 'working_directory': '/work/01131/tg804093/wrangler/work/spark-31fbbc48-f007-11e8-979a-549f3509766c', 'output': 'spark_job_spark-31fbbc48-f007-11e8-979a-549f3509766c.stdout', 'error': 'spark_job_spark-31fbbc48-f007-11e8-979a-549f3509766c.stderr', 'number_of_nodes': 2, 'cores_per_node': 48, 'project': 'TG-MCB090174', 'queue': 'normal', 'walltime': 59}\n",
      "DEBUG:pilot-streaming:Submit pilot job to: slurm+ssh://login1.wrangler.tacc.utexas.edu\n",
      "DEBUG:pilot-streaming:Type Job IDps-31fbe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpv7ned8u1\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmpv7ned8u1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: SSH run job finished\n",
      "DEBUG:pilot-streaming:Output - \n",
      "\n",
      "To access the system:\n",
      "\n",
      "1) If not using ssh-keys, please enter your TACC password at the password prompt\n",
      "2) At the TACC Token prompt, enter your 6-digit code followed by <return>.\n",
      "\n",
      "---------------------------------------------------------------\n",
      "          Welcome to the Wrangler Supercomputer                 \n",
      "---------------------------------------------------------------\n",
      "\n",
      "No reservation for this job\n",
      "--> Verifying valid submit host (login1)...OK\n",
      "--> Verifying valid jobname...OK\n",
      "--> Enforcing max jobs per user...OK\n",
      "--> Verifying availability of your home dir (/home/01131/tg804093)...OK\n",
      "--> Verifying availability of your work dir (/work/01131/tg804093/wrangler)...OK\n",
      "--> Verifying valid ssh keys...OK\n",
      "--> Verifying access to desired queue (normal)...OK\n",
      "--> Verifying job request is within current queue limits...OK\n",
      "--> Checking available allocation (TG-MCB090174)...OK\n",
      "Submitted batch job 91700\n",
      "\n",
      "DEBUG:pilot-streaming:Found SLURM Job ID: 91700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmpv7ned8u1\n",
      "**** Job: 91700 State : Queue\n",
      "Create Spark Context for URL: spark://129.114.58.101:7077\n",
      "Create Spark Context for URL: spark://129.114.58.101:7077\n",
      "CPU times: user 11 ms, sys: 25.4 ms, total: 36.4 ms\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "spark_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Spark Context for URL: spark://129.114.58.101:7077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spark_home': '/work/01131/tg804093/wrangler/work/spark-31fbbc48-f007-11e8-979a-549f3509766c/spark-2.4.0-bin-hadoop2.7',\n",
       " 'master_url': 'spark://129.114.58.101:7077',\n",
       " 'web_ui_url': 'http://129.114.58.101:8080'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:51:55.430862Z",
     "start_time": "2017-12-28T17:51:55.093479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Spark Context for URL: spark://129.114.58.101:7077\n"
     ]
    }
   ],
   "source": [
    "sc = spark_pilot.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.map(lambda a: a*a).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Cancel SLURM job\n"
     ]
    }
   ],
   "source": [
    "spark_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_of_nodes\": 1,\n",
    "    \"cores_per_node\": 48,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"kafka\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: Parsing job description\n",
      "DEBUG:pilot-streaming:Submit pilot job to: slurm://localhost\n",
      "DEBUG:pilot-streaming:Type Job IDps-c97bd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpt27cwoql\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmpt27cwoql\n",
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmpt27cwoql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: SSH run job finished\n",
      "DEBUG:pilot-streaming:Output - \n",
      "\n",
      "To access the system:\n",
      "\n",
      "1) If not using ssh-keys, please enter your TACC password at the password prompt\n",
      "2) At the TACC Token prompt, enter your 6-digit code followed by <return>.\n",
      "\n",
      "---------------------------------------------------------------\n",
      "          Welcome to the Wrangler Supercomputer                 \n",
      "---------------------------------------------------------------\n",
      "\n",
      "No reservation for this job\n",
      "--> Verifying valid submit host (login1)...OK\n",
      "--> Verifying valid jobname...OK\n",
      "--> Enforcing max jobs per user...OK\n",
      "--> Verifying availability of your home dir (/home/01131/tg804093)...OK\n",
      "--> Verifying availability of your work dir (/work/01131/tg804093/wrangler)...OK\n",
      "--> Verifying valid ssh keys...OK\n",
      "--> Verifying access to desired queue (normal)...OK\n",
      "--> Verifying job request is within current queue limits...OK\n",
      "--> Checking available allocation (TG-MCB090174)...OK\n",
      "Submitted batch job 91694\n",
      "\n",
      "DEBUG:pilot-streaming:Found SLURM Job ID: 91694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Job: 91694 State : Running\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-c979bff6-f003-11e8-8762-549f3509766c/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-c979bff6-f003-11e8-8762-549f3509766c/config (Sat Nov 24 10:12:49 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-101:9092', 'zookeeper.connect': 'c251-101:2181', 'zookeeper.connection.timeout.ms': '6000'}\n",
      "CPU times: user 12.4 ms, sys: 30.7 ms, total: 43.1 ms\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kafka_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "kafka_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-c979bff6-f003-11e8-8762-549f3509766c/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-c979bff6-f003-11e8-8762-549f3509766c/config (Sat Nov 24 10:12:49 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-101:9092', 'zookeeper.connect': 'c251-101:2181', 'zookeeper.connection.timeout.ms': '6000'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'master_url': 'c251-101:2181',\n",
       " 'details': {'broker.id': '0',\n",
       "  'listeners': 'PLAINTEXT://c251-101:9092',\n",
       "  'zookeeper.connect': 'c251-101:2181',\n",
       "  'zookeeper.connection.timeout.ms': '6000'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_of_nodes\": 1,\n",
    "    \"cores_per_node\": 48,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"dask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: Parsing job description\n",
      "DEBUG:pilot-streaming:Submit pilot job to: slurm://localhost\n",
      "DEBUG:pilot-streaming:Type Job IDps-1941d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp91sasdtm\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmp91sasdtm\n",
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmp91sasdtm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pilot-streaming:Pilot-Streaming SLURM: SSH run job finished\n",
      "DEBUG:pilot-streaming:Output - \n",
      "\n",
      "To access the system:\n",
      "\n",
      "1) If not using ssh-keys, please enter your TACC password at the password prompt\n",
      "2) At the TACC Token prompt, enter your 6-digit code followed by <return>.\n",
      "\n",
      "---------------------------------------------------------------\n",
      "          Welcome to the Wrangler Supercomputer                 \n",
      "---------------------------------------------------------------\n",
      "\n",
      "No reservation for this job\n",
      "--> Verifying valid submit host (login1)...OK\n",
      "--> Verifying valid jobname...OK\n",
      "--> Enforcing max jobs per user...OK\n",
      "--> Verifying availability of your home dir (/home/01131/tg804093)...OK\n",
      "--> Verifying availability of your work dir (/work/01131/tg804093/wrangler)...OK\n",
      "--> Verifying valid ssh keys...OK\n",
      "--> Verifying access to desired queue (normal)...OK\n",
      "--> Verifying job request is within current queue limits...OK\n",
      "--> Checking available allocation (TG-MCB090174)...OK\n",
      "Submitted batch job 91695\n",
      "\n",
      "DEBUG:pilot-streaming:Found SLURM Job ID: 91695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Job: 91695 State : Running\n",
      "CPU times: user 797 ms, sys: 186 ms, total: 983 ms\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dask_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "dask_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_url': 'tcp://c251-102:8786', 'web_ui_url': 'http://c251-102:8787'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': 'tcp://129.114.58.135:8786',\n",
       " 'id': 'Scheduler-363ae53b-1276-4ffc-bdc7-70b1aeb4283a',\n",
       " 'services': {'bokeh': 8787},\n",
       " 'type': 'Scheduler',\n",
       " 'workers': {'tcp://129.114.58.135:41796': {'cpu': 8.0,\n",
       "   'executing': 0,\n",
       "   'host': '129.114.58.135',\n",
       "   'in_flight': 0,\n",
       "   'in_memory': 10,\n",
       "   'last-seen': 1515036799.385555,\n",
       "   'last-task': 1515036750.2663264,\n",
       "   'local_directory': '/home/01131/tg804093/dask-worker-space/worker-lkiSY_',\n",
       "   'memory': 103673856,\n",
       "   'memory_limit': 134778585088,\n",
       "   'name': 'tcp://129.114.58.135:41796',\n",
       "   'ncores': 48,\n",
       "   'num_fds': 24,\n",
       "   'pid': 44991,\n",
       "   'read_bytes': 158293.4720896321,\n",
       "   'ready': 0,\n",
       "   'services': {'bokeh': 8789, 'nanny': 42225},\n",
       "   'time': 1515036798.885611,\n",
       "   'time-delay': 0.00038909912109375,\n",
       "   'write_bytes': 158293.4720896321}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distributed\n",
    "dask_client  = distributed.Client(dask_pilot.get_details()['master_url'])\n",
    "dask_client.scheduler_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_client.gather(dask_client.map(lambda a: a*a, range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
